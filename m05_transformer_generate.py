from pdf_reader import get_pdf_text
import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Set path to PDF document and extract text from page 1 to 1
doc_path_name = 'documents/chat_gpt_ubs.pdf'
doc_text = get_pdf_text(doc_path_name, 1, 1)

# Print number of input words in the document
print(f'num input words = {len(doc_text.split(" "))}')

# Load BART tokenizer
checkpoint = 'facebook/bart-large-cnn'
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Tokenize the input document using the BART tokenizer
# Note: By default, the tokenizer returns a list of Python integers
tokens = tokenizer(doc_text)

# Print number of input tokens generated by the tokenizer
print(f'num input tokens = {len(tokens["input_ids"])}')

# again only for understanding purpose the above step can be further split of above steps to see the intermediate values
# tokenized_text = tokenizer.tokenize(doc_text)
# print('tokenized text = ', type(tokenized_text), tokenized_text)
# print(f'num tokens = {len(tokenized_text)}')
# token_ids = tokenizer.convert_tokens_to_ids(tokenized_text)
# print('convert_tokens_to_ids', token_ids)
# decoded_string = tokenizer.decode(token_ids)
# print('decoded_string = ', decoded_string)



# Load the pre-trained BART model
model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)

# Tokenize the input document and convert to PyTorch tensor
tokenized_text = tokenizer(doc_text, return_tensors="pt")

# Generate a summary using the BART model
# Note: Here, we set max_new_tokens to 200, which means the maximum number of output tokens should be 200
outputs = model.generate(tokenized_text['input_ids'], min_new_tokens=100, max_new_tokens=200,
                         length_penalty=2.0, num_beams=4, do_sample=True)

# Print the number of output tokens generated by the BART model
print(f'num output token {outputs.shape}')

# Decode the output tokens to generate the summary string
output_str = tokenizer.decode(outputs[0], skip_special_tokens=True)

# Print the number of output words in the summary
print(f'num output words = {len(output_str.split(" "))}')

# Print the summary
print(f'summary = {output_str}')

